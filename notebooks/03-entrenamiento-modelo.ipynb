{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51a6a74-adaf-4fa7-8a0c-427570c6f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: 0.6738\n",
      "Epoch 2/20 - Loss: 0.0798\n",
      "Epoch 3/20 - Loss: 0.0129\n",
      "Epoch 4/20 - Loss: 0.0027\n",
      "Epoch 5/20 - Loss: 0.0007\n",
      "Epoch 6/20 - Loss: 0.0002\n",
      "Epoch 7/20 - Loss: 0.0001\n",
      "Epoch 8/20 - Loss: 0.0000\n",
      "Epoch 9/20 - Loss: 0.0000\n",
      "Epoch 10/20 - Loss: 0.0000\n",
      "Epoch 11/20 - Loss: 0.0000\n",
      "Epoch 12/20 - Loss: 0.0000\n",
      "Epoch 13/20 - Loss: 0.0000\n",
      "Epoch 14/20 - Loss: 0.0000\n",
      "Epoch 15/20 - Loss: 0.0000\n",
      "Epoch 16/20 - Loss: 0.0000\n",
      "Epoch 17/20 - Loss: 0.0000\n",
      "Epoch 18/20 - Loss: 0.0000\n",
      "Epoch 19/20 - Loss: 0.0000\n",
      "Epoch 20/20 - Loss: 0.0000\n",
      "Modelo guardado en: ../models/transit_cnn.pt\n",
      "Metadatos guardados en: ../models/transit_cnn_meta.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lightkurve import LightCurve\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "\n",
    "# ---------- CONFIGURACIÓN GENERAL ----------\n",
    "DATA_DIR = \"../data\"\n",
    "MODEL_PATH = \"../models/transit_cnn.pt\"\n",
    "META_PATH = \"../models/transit_cnn_meta.json\"\n",
    "INPUT_LENGTH = 2000  # longitud fija para todas las curvas\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ---------- FUNCIONES DE PREPROCESAMIENTO ----------\n",
    "\n",
    "def load_and_preprocess(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    lc = LightCurve(time=df[\"time\"], flux=df[\"flux\"])\n",
    "    flattened = lc.flatten(window_length=401)\n",
    "    flux = flattened.flux.value\n",
    "\n",
    "    # Normalización de longitud\n",
    "    if len(flux) < INPUT_LENGTH:\n",
    "        flux = np.pad(flux, (0, INPUT_LENGTH - len(flux)), mode=\"constant\", constant_values=0)\n",
    "    else:\n",
    "        flux = flux[:INPUT_LENGTH]\n",
    "\n",
    "    return flux.astype(np.float32)\n",
    "\n",
    "# ---------- DATASET CUSTOM ----------\n",
    "\n",
    "class ExoplanetDataset(Dataset):\n",
    "    def __init__(self, filepaths, labels):\n",
    "        self.filepaths = filepaths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        flux = load_and_preprocess(self.filepaths[idx])\n",
    "        flux_tensor = torch.tensor(flux).unsqueeze(0)  # (1, length)\n",
    "        label = torch.tensor([self.labels[idx]], dtype=torch.float32)\n",
    "        return flux_tensor, label\n",
    "\n",
    "# ---------- MODELO CNN ----------\n",
    "\n",
    "class TransitCNN(nn.Module):\n",
    "    def __init__(self, input_length):\n",
    "        super(TransitCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 8, kernel_size=5)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        conv_out_size = (input_length - 4) // 2\n",
    "        self.fc1 = nn.Linear(8 * conv_out_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# ---------- CARGA DE DATOS ----------\n",
    "# Simulación de ejemplos: 1 positivo, 1 negativo\n",
    "files = [\n",
    "    os.path.join(DATA_DIR, \"TIC_307210830.csv\"),  # supuesto positivo\n",
    "]\n",
    "labels = [1, 0]\n",
    "\n",
    "dataset = ExoplanetDataset(files, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ---------- ENTRENAMIENTO ----------\n",
    "model = TransitCNN(INPUT_LENGTH)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# ---------- GUARDADO ----------\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "with open(META_PATH, \"w\") as f:\n",
    "    json.dump({\"input_length\": INPUT_LENGTH}, f)\n",
    "\n",
    "print(f\"Modelo guardado en: {MODEL_PATH}\")\n",
    "print(f\"Metadatos guardados en: {META_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce7f07-6f6a-4cb8-8e29-1b727054935e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
